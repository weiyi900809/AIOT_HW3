#!/usr/bin/env python3
"""
Logistic Regression Phishing Detector - Streamlit æ‡‰ç”¨
äº’å‹•å¼å¯è¦–åŒ–å’Œé æ¸¬ç•Œé¢
"""

import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import joblib
from sklearn.preprocessing import StandardScaler
import warnings
warnings.filterwarnings('ignore')

# é é¢é…ç½®
st.set_page_config(
    page_title="ğŸ£ é‡£é­šç¶²ç«™åµæ¸¬ç³»çµ±",
    page_icon="ğŸ£",
    layout="wide",
    initial_sidebar_state="expanded"
)

# è‡ªå®šç¾©æ¨£å¼
st.markdown("""
    <style>
    .metric-card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        padding: 20px;
        border-radius: 10px;
        text-align: center;
        font-size: 18px;
        font-weight: bold;
    }
    .prediction-safe {
        background-color: #d4edda;
        border: 2px solid #28a745;
        padding: 15px;
        border-radius: 5px;
        color: #155724;
    }
    .prediction-danger {
        background-color: #f8d7da;
        border: 2px solid #dc3545;
        padding: 15px;
        border-radius: 5px;
        color: #721c24;
    }
    </style>
""", unsafe_allow_html=True)

# å¿«å–è¼‰å…¥æ¨¡å‹
@st.cache_resource
def load_models():
    """è¼‰å…¥è¨“ç·´å¥½çš„æ¨¡å‹"""
    try:
        model = joblib.load('phishing_logistic_model.pkl')
        scaler = joblib.load('phishing_scaler.pkl')
        metrics = joblib.load('phishing_metrics.pkl')
        return model, scaler, metrics
    except FileNotFoundError:
        return None, None, None

def main():
    st.title("ğŸ£ é‡£é­šç¶²ç«™åµæ¸¬ç³»çµ±")
    st.subheader("åŸºæ–¼ Logistic Regression çš„é‡£é­šæ”»æ“Šè­˜åˆ¥")
    
    # å´é‚Šæ¬„å°èˆª
    page = st.sidebar.radio("é¸æ“‡åŠŸèƒ½", ["ğŸ“Š å„€è¡¨æ¿", "ğŸ”® å³æ™‚é æ¸¬", "ğŸ“ˆ æ¨¡å‹è©•ä¼°", "â„¹ï¸ ç³»çµ±èªªæ˜"])
    
    model, scaler, metrics = load_models()
    
    if model is None:
        st.error("âŒ æ‰¾ä¸åˆ°æ¨¡å‹æª”æ¡ˆï¼Œè«‹å…ˆåŸ·è¡Œ train_phishing_model.py")
        return
    
    # ============================================
    # é é¢ 1: å„€è¡¨æ¿
    # ============================================
    if page == "ğŸ“Š å„€è¡¨æ¿":
        st.header("ğŸ“Š æ¨¡å‹æ€§èƒ½å„€è¡¨æ¿")
        
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("ğŸ¯ æ¸¬è©¦æº–ç¢ºç‡", f"{metrics['test_accuracy']:.2%}", 
                     delta=f"{(metrics['test_accuracy']-metrics['train_accuracy'])*100:.2f}%")
        with col2:
            st.metric("ğŸ¯ æ¸¬è©¦ç²¾æº–ç‡", f"{metrics['test_precision']:.2%}")
        with col3:
            st.metric("ğŸ¯ æ¸¬è©¦å¬å›ç‡", f"{metrics['test_recall']:.2%}")
        with col4:
            st.metric("ğŸ¯ F1 åˆ†æ•¸", f"{metrics['test_f1']:.4f}")
        
        st.divider()
        
        # æ€§èƒ½å°æ¯”è¡¨
        st.subheader("è¨“ç·´é›† vs æ¸¬è©¦é›†æ€§èƒ½å°æ¯”")
        comparison_df = pd.DataFrame({
            'æŒ‡æ¨™': ['æº–ç¢ºç‡', 'ç²¾æº–ç‡', 'å¬å›ç‡', 'F1 åˆ†æ•¸', 'AUC'],
            'è¨“ç·´é›†': [metrics['train_accuracy'], metrics['train_precision'], 
                     metrics['train_recall'], metrics['train_f1'], metrics['train_auc']],
            'æ¸¬è©¦é›†': [metrics['test_accuracy'], metrics['test_precision'], 
                     metrics['test_recall'], metrics['test_f1'], metrics['test_auc']]
        })
        
        st.dataframe(comparison_df, use_container_width=True)
        
        # è¦–è¦ºåŒ–
        fig, ax = plt.subplots(figsize=(10, 6))
        comparison_df.set_index('æŒ‡æ¨™')[['è¨“ç·´é›†', 'æ¸¬è©¦é›†']].plot(kind='bar', ax=ax, color=['#667eea', '#764ba2'])
        ax.set_title('æ¨¡å‹æ€§èƒ½å°æ¯”', fontweight='bold', fontsize=14)
        ax.set_ylabel('åˆ†æ•¸')
        ax.set_ylim(0, 1)
        ax.grid(axis='y', alpha=0.3)
        plt.xticks(rotation=45)
        st.pyplot(fig)
        
        st.info(f"âœ“ 5 æŠ˜äº¤å‰é©—è­‰å¹³å‡æº–ç¢ºç‡: {metrics['cv_mean']:.4f} (+/- {metrics['cv_std']:.4f})")
    
    # ============================================
    # é é¢ 2: å³æ™‚é æ¸¬
    # ============================================
    elif page == "ğŸ”® å³æ™‚é æ¸¬":
        st.header("ğŸ”® å³æ™‚é‡£é­šç¶²ç«™æª¢æ¸¬")
        
        st.info("ğŸ’¡ è¼¸å…¥é‡£é­šç¶²ç«™ç‰¹å¾µå€¼é€²è¡Œå³æ™‚é æ¸¬")
        
        # ç¯„ä¾‹ç‰¹å¾µæ•¸ (æ ¹æ“šå¯¦éš›è³‡æ–™é›†èª¿æ•´)
        num_features = scaler.n_features_in_
        
        col1, col2 = st.columns(2)
        
        feature_values = []
        for i in range(num_features):
            with col1 if i % 2 == 0 else col2:
                value = st.slider(
                    f"ç‰¹å¾µ {i+1}",
                    min_value=-5.0,
                    max_value=5.0,
                    value=0.0,
                    step=0.1
                )
                feature_values.append(value)
        
        if st.button("ğŸ” é€²è¡Œé æ¸¬", use_container_width=True):
            # æº–å‚™è¼¸å…¥
            features_array = np.array(feature_values).reshape(1, -1)
            
            # é€²è¡Œé æ¸¬
            prediction = model.predict(features_array)[0]
            probability = model.predict_proba(features_array)[0]
            
            st.divider()
            st.subheader("é æ¸¬çµæœ")
            
            if prediction == 1:
                st.markdown(
                    f"<div class='prediction-danger'><h3>âš ï¸ é‡£é­šç¶²ç«™ (Phishing)</h3><p>ç½®ä¿¡åº¦: {probability[1]:.2%}</p></div>",
                    unsafe_allow_html=True
                )
            else:
                st.markdown(
                    f"<div class='prediction-safe'><h3>âœ… æ­£å¸¸ç¶²ç«™ (Legitimate)</h3><p>ç½®ä¿¡åº¦: {probability[0]:.2%}</p></div>",
                    unsafe_allow_html=True
                )
            
            # è©³ç´°æ¦‚ç‡
            col1, col2 = st.columns(2)
            with col1:
                st.metric("æ­£å¸¸ç¶²ç«™æ¦‚ç‡", f"{probability[0]:.2%}")
            with col2:
                st.metric("é‡£é­šç¶²ç«™æ¦‚ç‡", f"{probability[1]:.2%}")
    
    # ============================================
    # é é¢ 3: æ¨¡å‹è©•ä¼°
    # ============================================
    elif page == "ğŸ“ˆ æ¨¡å‹è©•ä¼°":
        st.header("ğŸ“ˆ è©³ç´°æ¨¡å‹è©•ä¼°")
        
        tab1, tab2, tab3 = st.tabs(["æ€§èƒ½æŒ‡æ¨™", "ç‰¹å¾µåˆ†æ", "åœ–è¡¨"])
        
        with tab1:
            st.subheader("å®Œæ•´è©•ä¼°æŒ‡æ¨™")
            metrics_df = pd.DataFrame({
                'æŒ‡æ¨™': list(metrics.keys()),
                'æ•¸å€¼': [f"{v:.4f}" for v in metrics.values()]
            })
            st.dataframe(metrics_df, use_container_width=True)
        
        with tab2:
            st.subheader("æ¨¡å‹ä¿‚æ•¸")
            coefficients = model.coef_[0]
            coef_df = pd.DataFrame({
                'ç‰¹å¾µ': [f"ç‰¹å¾µ {i+1}" for i in range(len(coefficients))],
                'ä¿‚æ•¸': coefficients
            }).sort_values('ä¿‚æ•¸', key=abs, ascending=False)
            
            st.dataframe(coef_df, use_container_width=True)
            
            # ä¿‚æ•¸è¦–è¦ºåŒ–
            fig, ax = plt.subplots(figsize=(10, 6))
            colors = ['#28a745' if x > 0 else '#dc3545' for x in coef_df['ä¿‚æ•¸']]
            ax.barh(coef_df['ç‰¹å¾µ'], coef_df['ä¿‚æ•¸'], color=colors)
            ax.set_xlabel('ä¿‚æ•¸å€¼')
            ax.set_title('ç‰¹å¾µä¿‚æ•¸ (ç¶ =æ­£ç›¸é—œé‡£é­š, ç´…=è² ç›¸é—œé‡£é­š)', fontweight='bold')
            ax.axvline(x=0, color='black', linestyle='-', linewidth=0.5)
            st.pyplot(fig)
        
        with tab3:
            st.subheader("è¨“ç·´éç¨‹åœ–è¡¨")
            
            # é¡¯ç¤ºä¹‹å‰ç”Ÿæˆçš„åœ–è¡¨
            try:
                img1 = plt.imread('01_feature_distribution.png')
                st.image(img1, caption='ç‰¹å¾µåˆ†ä½ˆ', use_container_width=True)
            except:
                st.warning("ç‰¹å¾µåˆ†ä½ˆåœ–è¡¨æœªæ‰¾åˆ°")
            
            try:
                img2 = plt.imread('02_confusion_matrix_roc.png')
                st.image(img2, caption='æ··æ·†çŸ©é™£èˆ‡ ROC æ›²ç·š', use_container_width=True)
            except:
                st.warning("æ··æ·†çŸ©é™£åœ–è¡¨æœªæ‰¾åˆ°")
    
    # ============================================
    # é é¢ 4: ç³»çµ±èªªæ˜
    # ============================================
    elif page == "â„¹ï¸ ç³»çµ±èªªæ˜":
        st.header("â„¹ï¸ ç³»çµ±èªªæ˜")
        
        st.subheader("ğŸ“ é …ç›®ç°¡ä»‹")
        st.write("""
        é€™æ˜¯ä¸€å€‹åŸºæ–¼ **Logistic Regression** çš„é‡£é­šç¶²ç«™è‡ªå‹•åµæ¸¬ç³»çµ±ã€‚
        
        **æ ¸å¿ƒåŠŸèƒ½:**
        - ğŸ¤– ä½¿ç”¨é‚è¼¯è¿´æ­¸é€²è¡ŒäºŒå…ƒåˆ†é¡
        - ğŸ“Š è‡ªå‹•åŒ–å‰è™•ç†èˆ‡ç‰¹å¾µæ¨™æº–åŒ–
        - ğŸ“ˆ å®Œæ•´çš„æ¨¡å‹è©•ä¼°èˆ‡é©—è­‰
        - ğŸ”® å³æ™‚é æ¸¬èˆ‡ç½®ä¿¡åº¦å±•ç¤º
        """)
        
        st.subheader("ğŸ”§ å‰è™•ç†æ­¥é©Ÿ")
        st.write("""
        1. **è³‡æ–™è¼‰å…¥** - å¾ CSV è®€å–é‡£é­šç¶²ç«™è³‡æ–™
        2. **ç•°å¸¸å€¼æª¢æ¸¬** - ä½¿ç”¨ IQR æ–¹æ³•è­˜åˆ¥ç•°å¸¸å€¼
        3. **ç‰¹å¾µæ¨™æº–åŒ–** - StandardScaler æ­£è¦åŒ–æ‰€æœ‰ç‰¹å¾µ
        4. **æ•¸æ“šåˆ†å‰²** - 80:20 è¨“ç·´/æ¸¬è©¦åˆ†å‰²ï¼ˆåˆ†å±¤æŠ½æ¨£ï¼‰
        5. **æ¨¡å‹è¨“ç·´** - Logistic Regression æœ€å¤§ä¼¼ç„¶ä¼°è¨ˆ
        6. **æ¨¡å‹è©•ä¼°** - å¤šæŒ‡æ¨™è©•ä¼°èˆ‡äº¤å‰é©—è­‰
        """)
        
        st.subheader("ğŸ“Š è©•ä¼°æŒ‡æ¨™èªªæ˜")
        
        metrics_info = {
            "æº–ç¢ºç‡ (Accuracy)": "æ­£ç¢ºé æ¸¬ä½”ç¸½é æ¸¬çš„æ¯”ä¾‹",
            "ç²¾æº–ç‡ (Precision)": "åœ¨æ‰€æœ‰é æ¸¬ç‚ºé‡£é­šçš„ä¸­ï¼ŒçœŸæ­£æ˜¯é‡£é­šçš„æ¯”ä¾‹",
            "å¬å›ç‡ (Recall)": "åœ¨æ‰€æœ‰çœŸæ­£çš„é‡£é­šä¸­ï¼Œè¢«æ­£ç¢ºè­˜åˆ¥çš„æ¯”ä¾‹",
            "F1 åˆ†æ•¸": "ç²¾æº–ç‡å’Œå¬å›ç‡çš„èª¿å’Œå¹³å‡æ•¸",
            "AUC": "ROC æ›²ç·šä¸‹çš„é¢ç©ï¼Œè¶Šæ¥è¿‘ 1 è¶Šå¥½"
        }
        
        for metric, explanation in metrics_info.items():
            st.write(f"**{metric}**: {explanation}")
        
        st.subheader("ğŸ¯ ä½¿ç”¨æŒ‡å—")
        st.write("""
        1. é€²å…¥ã€Œå³æ™‚é æ¸¬ã€é é¢
        2. èª¿æ•´æ»‘å¡Šè¨­å®šç¶²ç«™ç‰¹å¾µå€¼
        3. é»æ“Šã€Œé€²è¡Œé æ¸¬ã€æŒ‰éˆ•
        4. æŸ¥çœ‹é æ¸¬çµæœèˆ‡ç½®ä¿¡åº¦
        """)

if __name__ == "__main__":
    main()
